{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWSL6fNAgJL_"
   },
   "source": [
    "# QuickStarter for the DataCrunch tournament \n",
    "\n",
    "## Basic steps and workflow:\n",
    "\n",
    "0. Using this notebook\n",
    "\n",
    "1. Download data\n",
    "\n",
    "2. Explore data\n",
    "\n",
    "3. Select a model\n",
    "\n",
    "4. Scoring\n",
    "\n",
    "5. Train / validation split\n",
    "\n",
    "6. Train your model \n",
    "\n",
    "7. Make prediction\n",
    "\n",
    "8. Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KuT0lsYgSV6",
    "tags": []
   },
   "source": [
    "## 0. Using this notebook \n",
    "\n",
    "To execute the cell press `shift+enter`. \n",
    "\n",
    "Follow the steps and login with your Google account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMwsPRjUayIr"
   },
   "outputs": [],
   "source": [
    "# Install the crunchDAO package - credit to @uuazed. Check here: https://github.com/uuazed/crunchdao\n",
    "!pip install --upgrade crunchdao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKQuFm3fdhmb"
   },
   "outputs": [],
   "source": [
    "# Lib & Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import gc\n",
    "\n",
    "import crunchdao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGIYhesjk9FJ"
   },
   "source": [
    "Paste <u>your</u> API key here. If you don't have one, go to the API management section of your account: https://account.crunchdao.com/account/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-b1mwFAeewn"
   },
   "outputs": [],
   "source": [
    "client = crunchdao.Client(apikey=\"\") # <= Your API key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJIm2ClNehoQ"
   },
   "outputs": [],
   "source": [
    "# Get the configuration of the current dataset\n",
    "client.dataset_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRMjw7K4goY2",
    "tags": []
   },
   "source": [
    "## 1. Download data\n",
    "\n",
    "Each week we will provide you with four DataFrames:\n",
    "\n",
    "- X_train contains the features;\n",
    "- y_train contains the targets;\n",
    "- X_test contains the features you can use in your models;\n",
    "- example_prediction contains an example of the submission awaited.\n",
    "\n",
    "There are 4 targets you need to predict: target_w, target_r, target_g, and target_b.\n",
    "\n",
    "You can either download the data in the *.csv* or *.parquet* extension.\n",
    "The *.csv* will take longer to download and take up more space in the RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzDnDouscYdO"
   },
   "outputs": [],
   "source": [
    "# Chose a file format between parquet and csv \n",
    "file_format = 'parquet'\n",
    "\n",
    "# Download current dataset\n",
    "client.download_data(directory=\".\", file_format=file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPfVnd0QgDu1"
   },
   "outputs": [],
   "source": [
    "if file_format == 'parquet':\n",
    "  # Data for training\n",
    "  train_features = pd.read_parquet(f'./X_train.{file_format}')\n",
    "  # Data for which you will submit your prediction\n",
    "  test_data = pd.read_parquet(f'./X_test.{file_format}')\n",
    "  # Targets use for your supervised training\n",
    "  train_targets = pd.read_parquet(f'./y_train.{file_format}')\n",
    "  # Exemple of an awaited submission\n",
    "  example_submission = pd.read_parquet(f'./example_submission.{file_format}')\n",
    "elif file_format == 'csv':\n",
    "  # Data for training\n",
    "  train_features = pd.read_csv(f'./X_train.{file_format}')\n",
    "  # Data for which you will submit your prediction\n",
    "  test_data = pd.read_csv(f'./X_test.{file_format}')\n",
    "  # Targets use for your supervised training\n",
    "  train_targets = pd.read_csv(f'./y_train.{file_format}')\n",
    "  # Exemple of an awaited submission\n",
    "  example_submission = pd.read_csv(f'./example_submission.{file_format}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s27mjZWMmQms"
   },
   "outputs": [],
   "source": [
    "# Merge train_features and train_targets for ease of use\n",
    "train_data = pd.merge(train_features, train_targets, on=['id', 'Moons'], how='inner')\n",
    "\n",
    "del train_features, train_targets\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfjoVR5-mS6R"
   },
   "outputs": [],
   "source": [
    "# Get the features columns name and the targets columns name\n",
    "features = [col for col in train_data.columns if 'Feature' in col]\n",
    "targets = [col for col in train_data.columns if 'target' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nl4puZY5mUVS"
   },
   "outputs": [],
   "source": [
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sngXvoomWpc",
    "tags": []
   },
   "source": [
    "## 2. Explore Data\n",
    "\n",
    "Observe your data and carefully prepare what you will give to your model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utryBiw3mgRt"
   },
   "outputs": [],
   "source": [
    "display(train_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bPDWRiX485n"
   },
   "source": [
    "### 2.1. Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEyt69QrInrE"
   },
   "outputs": [],
   "source": [
    "def show_cov(x):\n",
    "    cov = x.corr().abs().to_numpy()\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.heatmap(cov,vmin=0, vmax=1, cmap=\"cividis\")\n",
    "    plt.show()\n",
    "\n",
    "# Show last moon covariance matrix\n",
    "train_data_last = train_data[train_data['Moons'] == train_data['Moons'].max()]\n",
    "show_cov(train_data_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtYC3-HR5I5P"
   },
   "source": [
    "### 2.2. Data distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6ProxIhAcnv"
   },
   "outputs": [],
   "source": [
    "# Train data binning explained and plot\n",
    "hist = train_data[features].iloc[:, :9].hist(bins=30, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmaNa2CBAdWF"
   },
   "outputs": [],
   "source": [
    "# Target explained and plot\n",
    "hist = train_data[targets].hist(bins=30, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeByZUhBLQtP"
   },
   "source": [
    "### 2.3. Number of stocks overtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSrfM7pLLbcX"
   },
   "outputs": [],
   "source": [
    "# Show the number of stocks in each moon \n",
    "train_data.groupby('Moons', group_keys=False).id.count().plot(figsize=(20, 5), grid='on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNXpPrTvmoga",
    "tags": []
   },
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZQomfufmf0B"
   },
   "outputs": [],
   "source": [
    "def xg_boost_template(X_train, y_train, X_val, y_val, val_refs, target):\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', max_depth=3, learning_rate=0.01, n_estimators=50, n_jobs=-1, colsample_bytree=0.5)\n",
    "    model.fit(X_train, y_train[target], verbose=True)\n",
    "\n",
    "    # Test the spearman of your model on the X_test data\n",
    "    preds = pd.DataFrame(model.predict(X_val), columns=[target])\n",
    "    get_spearman_results(preds, y_val, val_refs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIde5ObYms88"
   },
   "source": [
    "## 4. Scoring: Spearman's rank correlation of your predictions vs the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbVUiR-JmrC6"
   },
   "outputs": [],
   "source": [
    "def get_spearman_results(preds, y_val, val_refs):\n",
    "    preds.rename({f'{target}':f'pred_{target.split(\"_\")[1]}' for target in preds.columns}, axis=1, inplace=True)\n",
    "    preds_ref = pd.concat([preds.reset_index(drop=True), val_refs.reset_index(drop=True), y_val.reset_index(drop=True)], axis=1)\n",
    "    spearman = pd.DataFrame()\n",
    "    \n",
    "    target_suffixes = [col.split('_')[-1] for col in preds.columns if 'pred' in col]\n",
    "    for suffix in target_suffixes:\n",
    "        spearman[f'target_{suffix}'] = preds_ref.groupby('Moons')[[f'pred_{suffix}', f'target_{suffix}']].corr(method='spearman').unstack().iloc[:,1]\n",
    "\n",
    "    print(f'\\nSpearman score over the period :\\n{spearman.describe()}\\n')\n",
    "    return spearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2La0RATmwrz"
   },
   "source": [
    "## 5. Embargoed Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtWYjoUgmw-X"
   },
   "outputs": [],
   "source": [
    "def train_test_split(data):\n",
    "    number_of_moons = len(data['Moons'].unique())\n",
    "    embargo = 13 # Embargo between train and test set\n",
    "    proportion = 0.8\n",
    "\n",
    "    # Train on 80% of the first moons and test on 20% of the last moons\n",
    "    train_set = data[data['Moons'] < int(number_of_moons * proportion) - embargo]\n",
    "    test_set = data[data['Moons'] > int(number_of_moons * proportion)]\n",
    "\n",
    "    X_train = train_set[features]\n",
    "    y_train = train_set[targets]\n",
    "    X_test = test_set[features]\n",
    "    y_test = test_set[targets]\n",
    "    test_refs = test_set.iloc[:, :2]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, test_refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qVkISCIm0bX"
   },
   "source": [
    "## 6. Supervised training of a simple XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M32AN238m0s0"
   },
   "outputs": [],
   "source": [
    "# Split your data to validate your model\n",
    "X_train, y_train, X_val, y_val, val_refs = train_test_split(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yyp9ry87m3j1"
   },
   "outputs": [],
   "source": [
    "# Run your model on the different targets\n",
    "model = {}\n",
    "for target in targets:\n",
    "  model[f'xgb_model_{target}'] = xg_boost_template(X_train, y_train, X_val, y_val, val_refs, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wri3oY3ZnDup"
   },
   "source": [
    "## 7. Make prediction on the 4 targets\n",
    "\n",
    "When you feel like your model is accurate enough it's time to predict the targets and submit your results.\n",
    "\n",
    "Predict on the 4 targets, concatenate the answers and submit.\n",
    "\n",
    "1. **WARNING**  Be sure that your columns are named id, Moons, target_w, target_r, etc.\n",
    "\n",
    "2. **WARNING** Your prediction must be in [0, 1].\n",
    "\n",
    "3. **WARNING** Don't submit constant values.\n",
    "\n",
    "4. **WARNING** Submit the id and the moon columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsKa78bMnEAy"
   },
   "outputs": [],
   "source": [
    "prediction = test_data.iloc[:, :2]\n",
    "for target in targets:\n",
    "    prediction.loc[:, target] = model[f'xgb_model_{target}'].predict(test_data.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0TasuS_nKN2"
   },
   "source": [
    "**Check your submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfVgBymanHb7"
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGHKnsURf6il"
   },
   "outputs": [],
   "source": [
    "def check_columns_name(df, sub):\n",
    "    if sub.columns.tolist() != df.columns.tolist():\n",
    "        raise Exception('Columns name are different from what is expected')\n",
    "\n",
    "def check_nans(sub):\n",
    "    if sub.isna().sum().sum() > 0:\n",
    "        raise Exception('NaNs detected')\n",
    "\n",
    "def check_values(sub, targets):\n",
    "    for target in targets:\n",
    "      if (sub.loc[:, target].values > 1).any() or (sub.loc[:, target].values < 0).any():\n",
    "          raise Exception('Values are not between 0 and 1')\n",
    "\n",
    "def check_moons(df, sub):\n",
    "    if set(df['Moons'].unique()) != set(sub['Moons'].unique()):\n",
    "        raise Exception('Moons are different from what is expected')\n",
    "\n",
    "def check_ids(df, sub, moon):\n",
    "    if not set(sub[sub['Moons'] == moon]['id'].unique()) == set(df[df['Moons'] == moon]['id'].unique()):\n",
    "        raise Exception('At least an id is missing')\n",
    "\n",
    "def check_constants(sub, moon, targets):\n",
    "    for target in targets:\n",
    "        if sub[sub['Moons'] == moon][target].nunique() == 1:\n",
    "            raise Exception('Constant values have been detected on a moon')\n",
    "\n",
    "try:\n",
    "    check_columns_name(example_submission, prediction)\n",
    "    check_nans(prediction)\n",
    "    check_values(prediction, targets)\n",
    "    check_moons(example_submission, prediction)\n",
    "    for moon in prediction['Moons'].unique():\n",
    "        check_ids(example_submission, prediction, moon)\n",
    "        check_constants(prediction, moon, targets)\n",
    "    print(f'Submission: OK')\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44rcH-bZnaYd"
   },
   "source": [
    "## 8. Submit predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-fnLyNaf9CV"
   },
   "outputs": [],
   "source": [
    "# Upload predictions\n",
    "submission_id = client.upload(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opfmKq8Yi4ns"
   },
   "outputs": [],
   "source": [
    "# Set a comment for the submission, to remember which model that is, etc...\n",
    "client.set_comment(submission_id, \"quickstart model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVP4EiUxneKp"
   },
   "outputs": [],
   "source": [
    "# Download your prediction file if you prefer submitting through the website\n",
    "from google.colab import files\n",
    "with open(\"prediction.csv\", \"wb\") as f:\n",
    "    f.write(prediction.to_csv(index=False).encode('ascii'))\n",
    "files.download('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKIwtJ2ofp7U"
   },
   "outputs": [],
   "source": [
    "# Check your past submissions\n",
    "client.submissions(\n",
    "    user_id=None, # None is your id by default \n",
    "    round_num=None # None shows all the round by default\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHi8HLtVnt5-",
    "tags": []
   },
   "source": [
    "## Useful links\n",
    "\n",
    "**Website**\n",
    "\n",
    "- https://www.crunchdao.com/\n",
    "\n",
    "**Social media**\n",
    "- discord : https://discord.gg/9wvzxS7A (come say hi! ðŸ˜‰)\n",
    "- twitter : https://twitter.com/CrunchDAO\n",
    "- linkedin : https://www.linkedin.com/company/crunchdao-com/\n",
    "- reddit : https://www.reddit.com/r/crunchdao/\n",
    "\n",
    "**Documentation**\n",
    "\n",
    "- https://docs.crunchdao.com/tournament/getting-started\n",
    "\n",
    "**Github**\n",
    "\n",
    "- https://github.com/crunchdao/\n",
    "- https://github.com/uuazed/crunchdao\n",
    "\n",
    "**DeSci - research framework**\n",
    "\n",
    "- https://desci.crunchdao.com/projects/crunchdao"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
